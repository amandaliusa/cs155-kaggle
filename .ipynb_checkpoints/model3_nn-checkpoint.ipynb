{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanda\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col=0)\n",
    "df_test = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_price                   0\n",
      "mid                          0\n",
      "opened_position_qty     172460\n",
      "closed_position_qty     172460\n",
      "transacted_qty               0\n",
      "d_open_interest              0\n",
      "bid1                         0\n",
      "bid2                         0\n",
      "bid3                         0\n",
      "bid4                         0\n",
      "bid5                         0\n",
      "ask1                         0\n",
      "ask2                         0\n",
      "ask3                         0\n",
      "ask4                         0\n",
      "ask5                         0\n",
      "bid1vol                      0\n",
      "bid2vol                      0\n",
      "bid3vol                      0\n",
      "bid4vol                      0\n",
      "bid5vol                      0\n",
      "ask1vol                      0\n",
      "ask2vol                      0\n",
      "ask3vol                      0\n",
      "ask4vol                      0\n",
      "ask5vol                      0\n",
      "y                            0\n",
      "dtype: int64\n",
      "last_price                  0\n",
      "mid                         0\n",
      "opened_position_qty     53656\n",
      "closed_position_qty     53656\n",
      "transacted_qty              0\n",
      "d_open_interest             0\n",
      "bid1                        0\n",
      "bid2                        0\n",
      "bid3                        0\n",
      "bid4                        0\n",
      "bid5                        0\n",
      "ask1                        0\n",
      "ask2                        0\n",
      "ask3                        0\n",
      "ask4                        0\n",
      "ask5                        0\n",
      "bid1vol                     0\n",
      "bid2vol                     0\n",
      "bid3vol                     0\n",
      "bid4vol                     0\n",
      "bid5vol                     0\n",
      "ask1vol                     0\n",
      "ask2vol                     0\n",
      "ask3vol                     0\n",
      "ask4vol                     0\n",
      "ask5vol                     0\n",
      "dtype: int64\n",
      "1.4005834444656124\n",
      "1.0\n",
      "1.9642765288626405\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# identify and replace missing values\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())\n",
    "\n",
    "print(df_train['opened_position_qty '].mean())\n",
    "print(df_train['opened_position_qty '].median())\n",
    "\n",
    "print(df_train['closed_position_qty'].mean())\n",
    "print(df_train['closed_position_qty'].median())\n",
    "\n",
    "# replace missing values with median (less sensitive to outliers)\n",
    "df_train['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_test['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_train['closed_position_qty'].fillna(df_train['closed_position_qty'].median(),inplace=True)\n",
    "df_test['closed_position_qty'].fillna(df_train['closed_position_qty'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_price       mid  opened_position_qty   closed_position_qty  \\\n",
      "id                                                                    \n",
      "1    -1.501678 -1.494346              2.464481            21.097156   \n",
      "2    -1.487008 -1.483343              2.987055            33.581616   \n",
      "3    -1.489453 -1.494346              0.896758            14.409052   \n",
      "4    -1.496788 -1.498013              0.896758            16.192547   \n",
      "6    -1.491898 -1.483343              0.374183            15.746673   \n",
      "\n",
      "    transacted_qty  d_open_interest      bid1      bid2      bid3      bid4  \\\n",
      "id                                                                            \n",
      "1        13.913985       -18.265229 -1.496986 -1.496637 -1.498903 -1.501215   \n",
      "2        21.583751       -29.330098 -1.487205 -1.486856 -1.489121 -1.488987   \n",
      "3         9.153441       -12.732794 -1.496986 -1.496637 -1.498903 -1.501215   \n",
      "4        10.211339       -14.860654 -1.499431 -1.501527 -1.503794 -1.503661   \n",
      "6         9.682390       -14.435082 -1.487205 -1.489301 -1.489121 -1.488987   \n",
      "\n",
      "      ...      bid1vol   bid2vol   bid3vol   bid4vol   bid5vol   ask1vol  \\\n",
      "id    ...                                                                  \n",
      "1     ...     0.742043  0.214423  1.050471 -0.802783  0.011052 -0.640954   \n",
      "2     ...    -0.194855 -0.766254 -0.242980  2.686636  0.970130 -0.640954   \n",
      "3     ...     1.444717  1.587372  1.235250 -0.628312 -0.308641 -0.419008   \n",
      "4     ...     2.381615  1.391237 -0.612538 -0.628312 -0.308641 -0.640954   \n",
      "6     ...    -0.663305  0.410559 -0.797316 -0.802783  1.769362  1.578509   \n",
      "\n",
      "     ask2vol   ask3vol   ask4vol   ask5vol  \n",
      "id                                          \n",
      "1  -0.168154 -0.221125 -0.708799  1.013890  \n",
      "2   2.040907  0.792224 -0.247674  0.440440  \n",
      "3   0.384111 -0.727800 -0.555091  0.727165  \n",
      "4  -0.352242 -0.727800  0.828287  1.300615  \n",
      "6   1.856818  0.792224 -0.401382  0.440440  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train = df_train[df_train.columns[:26]]\n",
    "y_train = df_train['y']\n",
    "x_test = df_test\n",
    "\n",
    "# Normalize training data by subtracting mean and scaling to unit variance\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_norm = std_scale.transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_norm, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "# Normalize testing data by using mean and SD of training set\n",
    "x_test_norm = std_scale.transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_norm, index=x_test.index, columns=x_test.columns) \n",
    "print(x_train.iloc[np.array([1, 2, 3, 4, 6])])\n",
    "#print(df_train.loc[df_train['id'] < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(x_train.shape[1],)),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(90, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(2, activation=  'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <tensorflow.python.keras.optimizers.Adam object at 0x00000220DE628B70>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8599e4325793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model.compile(optimizer = tf.keras.optimizers.Adam(),\n\u001b[0;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m               metrics=['accuracy'])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         raise ValueError('Could not interpret optimizer identifier: ' +\n\u001b[1;32m--> 793\u001b[1;33m                          str(identifier))\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <tensorflow.python.keras.optimizers.Adam object at 0x00000220DE628B70>"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fold = 10\n",
    "index = np.array(range(len(x_train)))\n",
    "train_error = 0\n",
    "val_error = 0\n",
    "kf = KFold(n_splits=num_fold)\n",
    "for train_index, test_index in kf.split(index):\n",
    "    x_train_val, x_test_val = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "    y_train_val, y_test_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    train_model = model.fit(x_train_val, y_train_val, epochs= 10, batch_size = 128)\n",
    "    eval_train = model.evaluate(x_train_val, y_train_val)\n",
    "    eval_test = model.evaluate(x_test_val, y_test_val)\n",
    "    train_error += eval_train[1] / num_fold\n",
    "    val_error += eval_test[1] / num_fold\n",
    "print(\"In Sample Accuracy: \" + str(train_error))\n",
    "print(\"Out of Sample Accuracy: \" + str(val_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = model.predict_proba(x_test)[:,1]\n",
    "df_test[['Predicted']].to_csv('submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
