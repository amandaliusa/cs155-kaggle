{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col=0)\n",
    "df_test = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with median (less sensitive to outliers)\n",
    "df_train['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_test['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_train['closed_position_qty'].fillna(df_train['closed_position_qty'].median(),inplace=True)\n",
    "df_test['closed_position_qty'].fillna(df_train['closed_position_qty'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train,df_test],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer new features by grouping like features \n",
    "bid_cols = ['bid1','bid2', 'bid3', 'bid4', 'bid5']\n",
    "bid_vol_cols = ['bid1vol', 'bid2vol', 'bid3vol', 'bid4vol', 'bid5vol']\n",
    "ask_cols = ['ask1', 'ask2', 'ask3', 'ask4', 'ask5',]\n",
    "ask_vol_cols = ['ask1vol','ask2vol', 'ask3vol', 'ask4vol', 'ask5vol']\n",
    "group_cols = {\"bid_cols\":bid_cols,\"bid_vol_cols\":bid_vol_cols,\"ask_cols\":ask_cols,\"ask_vol_cols\":ask_vol_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bid_cols\n",
      "bid_vol_cols\n",
      "ask_cols\n",
      "ask_vol_cols\n"
     ]
    }
   ],
   "source": [
    "for group in group_cols.keys():\n",
    "    print(group)\n",
    "    df[f\"{group}_max\"] = df[group_cols[group]].max(axis=1)\n",
    "    df[f\"{group}_min\"] = df[group_cols[group]].min(axis=1)\n",
    "    df[f\"{group}_spread\"] = df[f\"{group}_max\"].div(df[f\"{group}_min\"])\n",
    "    #df[f\"{group}_logsumexp\"] = df[group_cols[group]].apply(logsumexp)\n",
    "    \n",
    "    df[f\"{group}_max\"] = df[group_cols[group]].max(axis=1)\n",
    "    \n",
    "df[\"last_price_div__mid\"] = df[\"last_price\"].div(df[\"mid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.loc[~df.y.isna()]\n",
    "y_train = x_train['y']\n",
    "x_train = x_train.drop(['y'], axis=1)\n",
    "x_test = df.loc[df.y.isna()]\n",
    "x_test = x_test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-8cd351f26dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Normalize testing data by using mean and SD of training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mx_test_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd_scale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y, copy)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         X = check_array(X, accept_sparse='csr', copy=copy, warn_on_dtype=True,\n\u001b[1;32m--> 681\u001b[1;33m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# # Normalize training data by subtracting mean and scaling to unit variance\n",
    "# std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "# x_train_norm = std_scale.transform(x_train)\n",
    "# x_train = pd.DataFrame(x_train_norm, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "# # Normalize testing data by using mean and SD of training set\n",
    "# x_test_norm = std_scale.transform(x_test)\n",
    "# x_test = pd.DataFrame(x_test_norm, index=x_test.index, columns=x_test.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and validation data \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(x_train.shape[1],)),\n",
    "#     keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "#     keras.layers.Dense(2, activation=  'softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "473904/473904 [==============================] - 29s 61us/step - loss: 5.7640 - acc: 0.6424\n",
      "Epoch 2/5\n",
      "473904/473904 [==============================] - 28s 59us/step - loss: 5.7611 - acc: 0.6426\n",
      "Epoch 3/5\n",
      "473904/473904 [==============================] - 28s 59us/step - loss: 5.7610 - acc: 0.6426\n",
      "Epoch 4/5\n",
      "473904/473904 [==============================] - ETA: 0s - loss: 5.7609 - acc: 0.642 - 33s 70us/step - loss: 5.7610 - acc: 0.6426\n",
      "Epoch 5/5\n",
      "473904/473904 [==============================] - 33s 69us/step - loss: 5.7610 - acc: 0.6426\n"
     ]
    }
   ],
   "source": [
    "train_model = model.fit(x_train, y_train, epochs= 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118476/118476 [==============================] - 7s 60us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.723423116103042, 0.6449069853820116]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = model.predict_proba(x_test)[:,1]\n",
    "df_test[['Predicted']].to_csv('submission_model9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6791724\ttest: 0.6791419\tbest: 0.6791419 (0)\ttotal: 276ms\tremaining: 46m 1s\n",
      "10:\tlearn: 0.6256668\ttest: 0.6256316\tbest: 0.6256316 (10)\ttotal: 2.26s\tremaining: 34m 15s\n",
      "20:\tlearn: 0.6169325\ttest: 0.6170271\tbest: 0.6170271 (20)\ttotal: 4.18s\tremaining: 33m 8s\n",
      "30:\tlearn: 0.6143109\ttest: 0.6146266\tbest: 0.6146266 (30)\ttotal: 6.47s\tremaining: 34m 40s\n",
      "40:\tlearn: 0.6132224\ttest: 0.6136518\tbest: 0.6136518 (40)\ttotal: 8.62s\tremaining: 34m 54s\n",
      "50:\tlearn: 0.6125415\ttest: 0.6131452\tbest: 0.6131452 (50)\ttotal: 10.7s\tremaining: 34m 42s\n",
      "60:\tlearn: 0.6120820\ttest: 0.6128760\tbest: 0.6128760 (60)\ttotal: 12.8s\tremaining: 34m 39s\n",
      "70:\tlearn: 0.6117279\ttest: 0.6126955\tbest: 0.6126955 (70)\ttotal: 15.5s\tremaining: 36m 12s\n",
      "80:\tlearn: 0.6114520\ttest: 0.6125372\tbest: 0.6125372 (80)\ttotal: 17.7s\tremaining: 36m 11s\n",
      "90:\tlearn: 0.6111768\ttest: 0.6123898\tbest: 0.6123898 (90)\ttotal: 19.8s\tremaining: 35m 57s\n",
      "100:\tlearn: 0.6109619\ttest: 0.6123162\tbest: 0.6123162 (100)\ttotal: 22s\tremaining: 35m 55s\n",
      "110:\tlearn: 0.6107223\ttest: 0.6121989\tbest: 0.6121989 (110)\ttotal: 24.1s\tremaining: 35m 47s\n",
      "120:\tlearn: 0.6104963\ttest: 0.6121195\tbest: 0.6121195 (120)\ttotal: 26.8s\tremaining: 36m 31s\n",
      "130:\tlearn: 0.6102014\ttest: 0.6119454\tbest: 0.6119454 (130)\ttotal: 29.2s\tremaining: 36m 38s\n",
      "140:\tlearn: 0.6098911\ttest: 0.6117982\tbest: 0.6117982 (140)\ttotal: 31.7s\tremaining: 36m 57s\n",
      "150:\tlearn: 0.6095871\ttest: 0.6116781\tbest: 0.6116781 (150)\ttotal: 34s\tremaining: 37m\n",
      "160:\tlearn: 0.6092845\ttest: 0.6115420\tbest: 0.6115420 (160)\ttotal: 37s\tremaining: 37m 42s\n",
      "170:\tlearn: 0.6090323\ttest: 0.6114400\tbest: 0.6114400 (170)\ttotal: 39.6s\tremaining: 37m 53s\n",
      "180:\tlearn: 0.6087689\ttest: 0.6113738\tbest: 0.6113738 (180)\ttotal: 42.1s\tremaining: 38m 5s\n",
      "190:\tlearn: 0.6084654\ttest: 0.6113001\tbest: 0.6113001 (190)\ttotal: 44.5s\tremaining: 38m 5s\n",
      "200:\tlearn: 0.6082143\ttest: 0.6112208\tbest: 0.6112161 (199)\ttotal: 46.8s\tremaining: 38m 2s\n",
      "210:\tlearn: 0.6079870\ttest: 0.6111977\tbest: 0.6111977 (210)\ttotal: 49.2s\tremaining: 38m 1s\n",
      "220:\tlearn: 0.6077318\ttest: 0.6110949\tbest: 0.6110949 (220)\ttotal: 51.5s\tremaining: 37m 58s\n",
      "230:\tlearn: 0.6074875\ttest: 0.6110469\tbest: 0.6110469 (230)\ttotal: 53.8s\tremaining: 37m 56s\n",
      "240:\tlearn: 0.6072319\ttest: 0.6110059\tbest: 0.6110059 (240)\ttotal: 56.4s\tremaining: 38m 5s\n",
      "250:\tlearn: 0.6070242\ttest: 0.6109530\tbest: 0.6109530 (250)\ttotal: 58.8s\tremaining: 38m 2s\n",
      "260:\tlearn: 0.6067668\ttest: 0.6108493\tbest: 0.6108493 (260)\ttotal: 1m 1s\tremaining: 37m 59s\n",
      "270:\tlearn: 0.6065484\ttest: 0.6108001\tbest: 0.6107956 (268)\ttotal: 1m 3s\tremaining: 37m 49s\n",
      "280:\tlearn: 0.6063387\ttest: 0.6107642\tbest: 0.6107642 (280)\ttotal: 1m 5s\tremaining: 37m 43s\n",
      "290:\tlearn: 0.6060992\ttest: 0.6107279\tbest: 0.6107279 (290)\ttotal: 1m 7s\tremaining: 37m 41s\n",
      "300:\tlearn: 0.6058877\ttest: 0.6106689\tbest: 0.6106689 (300)\ttotal: 1m 10s\tremaining: 37m 37s\n",
      "310:\tlearn: 0.6056760\ttest: 0.6106130\tbest: 0.6106130 (310)\ttotal: 1m 12s\tremaining: 37m 33s\n",
      "320:\tlearn: 0.6054838\ttest: 0.6105855\tbest: 0.6105803 (318)\ttotal: 1m 14s\tremaining: 37m 31s\n",
      "330:\tlearn: 0.6052873\ttest: 0.6105630\tbest: 0.6105614 (329)\ttotal: 1m 16s\tremaining: 37m 27s\n",
      "340:\tlearn: 0.6050717\ttest: 0.6105201\tbest: 0.6105201 (340)\ttotal: 1m 19s\tremaining: 37m 25s\n",
      "350:\tlearn: 0.6048708\ttest: 0.6104761\tbest: 0.6104761 (350)\ttotal: 1m 21s\tremaining: 37m 31s\n",
      "360:\tlearn: 0.6046621\ttest: 0.6104446\tbest: 0.6104446 (360)\ttotal: 1m 24s\tremaining: 37m 29s\n",
      "370:\tlearn: 0.6044778\ttest: 0.6104077\tbest: 0.6104077 (370)\ttotal: 1m 26s\tremaining: 37m 28s\n",
      "380:\tlearn: 0.6042707\ttest: 0.6103756\tbest: 0.6103756 (380)\ttotal: 1m 28s\tremaining: 37m 23s\n",
      "390:\tlearn: 0.6040724\ttest: 0.6103458\tbest: 0.6103452 (387)\ttotal: 1m 31s\tremaining: 37m 20s\n",
      "400:\tlearn: 0.6039176\ttest: 0.6103108\tbest: 0.6103108 (400)\ttotal: 1m 33s\tremaining: 37m 17s\n",
      "410:\tlearn: 0.6037274\ttest: 0.6102678\tbest: 0.6102678 (410)\ttotal: 1m 35s\tremaining: 37m 10s\n",
      "420:\tlearn: 0.6035228\ttest: 0.6102744\tbest: 0.6102576 (412)\ttotal: 1m 37s\tremaining: 37m 8s\n",
      "430:\tlearn: 0.6033259\ttest: 0.6102488\tbest: 0.6102488 (430)\ttotal: 1m 40s\tremaining: 37m 6s\n",
      "440:\tlearn: 0.6031447\ttest: 0.6102296\tbest: 0.6102233 (435)\ttotal: 1m 42s\tremaining: 37m 7s\n",
      "450:\tlearn: 0.6029766\ttest: 0.6102136\tbest: 0.6102136 (450)\ttotal: 1m 45s\tremaining: 37m 13s\n",
      "460:\tlearn: 0.6028089\ttest: 0.6101843\tbest: 0.6101843 (460)\ttotal: 1m 48s\tremaining: 37m 22s\n",
      "470:\tlearn: 0.6026279\ttest: 0.6101758\tbest: 0.6101756 (468)\ttotal: 1m 50s\tremaining: 37m 18s\n",
      "480:\tlearn: 0.6024686\ttest: 0.6101618\tbest: 0.6101613 (479)\ttotal: 1m 53s\tremaining: 37m 33s\n",
      "490:\tlearn: 0.6022905\ttest: 0.6101319\tbest: 0.6101319 (490)\ttotal: 1m 57s\tremaining: 37m 58s\n",
      "500:\tlearn: 0.6021400\ttest: 0.6100938\tbest: 0.6100938 (500)\ttotal: 2m 1s\tremaining: 38m 23s\n",
      "510:\tlearn: 0.6019361\ttest: 0.6100475\tbest: 0.6100475 (510)\ttotal: 2m 3s\tremaining: 38m 19s\n",
      "520:\tlearn: 0.6017402\ttest: 0.6100207\tbest: 0.6100207 (520)\ttotal: 2m 6s\tremaining: 38m 21s\n",
      "530:\tlearn: 0.6015562\ttest: 0.6099950\tbest: 0.6099950 (530)\ttotal: 2m 9s\tremaining: 38m 32s\n",
      "540:\tlearn: 0.6013636\ttest: 0.6099883\tbest: 0.6099851 (538)\ttotal: 2m 13s\tremaining: 38m 55s\n",
      "550:\tlearn: 0.6011881\ttest: 0.6099920\tbest: 0.6099851 (538)\ttotal: 2m 16s\tremaining: 38m 52s\n",
      "560:\tlearn: 0.6010265\ttest: 0.6099727\tbest: 0.6099727 (560)\ttotal: 2m 18s\tremaining: 38m 46s\n",
      "570:\tlearn: 0.6008782\ttest: 0.6099759\tbest: 0.6099616 (565)\ttotal: 2m 20s\tremaining: 38m 43s\n",
      "580:\tlearn: 0.6006975\ttest: 0.6099428\tbest: 0.6099428 (580)\ttotal: 2m 22s\tremaining: 38m 36s\n",
      "590:\tlearn: 0.6005385\ttest: 0.6099428\tbest: 0.6099346 (584)\ttotal: 2m 24s\tremaining: 38m 28s\n",
      "600:\tlearn: 0.6003790\ttest: 0.6099186\tbest: 0.6099124 (599)\ttotal: 2m 27s\tremaining: 38m 21s\n",
      "610:\tlearn: 0.6001983\ttest: 0.6098806\tbest: 0.6098806 (610)\ttotal: 2m 29s\tremaining: 38m 13s\n",
      "620:\tlearn: 0.6000423\ttest: 0.6098535\tbest: 0.6098487 (617)\ttotal: 2m 32s\tremaining: 38m 16s\n",
      "630:\tlearn: 0.5998559\ttest: 0.6098058\tbest: 0.6098058 (630)\ttotal: 2m 34s\tremaining: 38m 12s\n",
      "640:\tlearn: 0.5996861\ttest: 0.6097790\tbest: 0.6097790 (640)\ttotal: 2m 36s\tremaining: 38m 5s\n",
      "650:\tlearn: 0.5995183\ttest: 0.6097689\tbest: 0.6097689 (650)\ttotal: 2m 38s\tremaining: 37m 58s\n",
      "660:\tlearn: 0.5993645\ttest: 0.6097573\tbest: 0.6097498 (657)\ttotal: 2m 42s\tremaining: 38m 9s\n",
      "670:\tlearn: 0.5991966\ttest: 0.6097296\tbest: 0.6097296 (670)\ttotal: 2m 45s\tremaining: 38m 18s\n",
      "680:\tlearn: 0.5990167\ttest: 0.6097028\tbest: 0.6097028 (680)\ttotal: 2m 48s\tremaining: 38m 25s\n",
      "690:\tlearn: 0.5988365\ttest: 0.6096558\tbest: 0.6096558 (690)\ttotal: 2m 52s\tremaining: 38m 43s\n",
      "700:\tlearn: 0.5986683\ttest: 0.6096332\tbest: 0.6096332 (700)\ttotal: 2m 54s\tremaining: 38m 38s\n",
      "710:\tlearn: 0.5985254\ttest: 0.6096398\tbest: 0.6096267 (703)\ttotal: 2m 57s\tremaining: 38m 35s\n",
      "720:\tlearn: 0.5983696\ttest: 0.6096198\tbest: 0.6096158 (718)\ttotal: 3m\tremaining: 38m 48s\n",
      "730:\tlearn: 0.5982336\ttest: 0.6096102\tbest: 0.6096093 (729)\ttotal: 3m 3s\tremaining: 38m 48s\n",
      "740:\tlearn: 0.5980972\ttest: 0.6096187\tbest: 0.6096093 (729)\ttotal: 3m 6s\tremaining: 38m 52s\n",
      "750:\tlearn: 0.5979239\ttest: 0.6096194\tbest: 0.6096093 (729)\ttotal: 3m 10s\tremaining: 39m 5s\n",
      "760:\tlearn: 0.5977484\ttest: 0.6096071\tbest: 0.6096071 (760)\ttotal: 3m 13s\tremaining: 39m 5s\n",
      "770:\tlearn: 0.5975920\ttest: 0.6096181\tbest: 0.6096057 (762)\ttotal: 3m 15s\tremaining: 38m 57s\n",
      "780:\tlearn: 0.5974298\ttest: 0.6095978\tbest: 0.6095978 (780)\ttotal: 3m 17s\tremaining: 38m 50s\n",
      "790:\tlearn: 0.5972597\ttest: 0.6095798\tbest: 0.6095798 (790)\ttotal: 3m 19s\tremaining: 38m 43s\n",
      "800:\tlearn: 0.5971042\ttest: 0.6095720\tbest: 0.6095691 (799)\ttotal: 3m 21s\tremaining: 38m 37s\n",
      "810:\tlearn: 0.5969677\ttest: 0.6095712\tbest: 0.6095691 (799)\ttotal: 3m 25s\tremaining: 38m 47s\n",
      "820:\tlearn: 0.5968320\ttest: 0.6095773\tbest: 0.6095664 (814)\ttotal: 3m 28s\tremaining: 38m 50s\n",
      "830:\tlearn: 0.5966804\ttest: 0.6095643\tbest: 0.6095643 (830)\ttotal: 3m 30s\tremaining: 38m 42s\n",
      "840:\tlearn: 0.5965191\ttest: 0.6095305\tbest: 0.6095305 (840)\ttotal: 3m 32s\tremaining: 38m 35s\n",
      "850:\tlearn: 0.5963444\ttest: 0.6095147\tbest: 0.6095077 (847)\ttotal: 3m 34s\tremaining: 38m 30s\n",
      "860:\tlearn: 0.5961983\ttest: 0.6095043\tbest: 0.6094986 (858)\ttotal: 3m 37s\tremaining: 38m 24s\n",
      "870:\tlearn: 0.5960647\ttest: 0.6094949\tbest: 0.6094939 (869)\ttotal: 3m 39s\tremaining: 38m 17s\n",
      "880:\tlearn: 0.5958886\ttest: 0.6094629\tbest: 0.6094629 (880)\ttotal: 3m 41s\tremaining: 38m 11s\n",
      "890:\tlearn: 0.5957374\ttest: 0.6094586\tbest: 0.6094571 (883)\ttotal: 3m 43s\tremaining: 38m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900:\tlearn: 0.5955947\ttest: 0.6094426\tbest: 0.6094367 (898)\ttotal: 3m 45s\tremaining: 37m 55s\n",
      "910:\tlearn: 0.5954531\ttest: 0.6094727\tbest: 0.6094367 (898)\ttotal: 3m 47s\tremaining: 37m 48s\n",
      "920:\tlearn: 0.5953115\ttest: 0.6094552\tbest: 0.6094367 (898)\ttotal: 3m 49s\tremaining: 37m 41s\n",
      "930:\tlearn: 0.5951446\ttest: 0.6094487\tbest: 0.6094367 (898)\ttotal: 3m 51s\tremaining: 37m 34s\n",
      "940:\tlearn: 0.5949925\ttest: 0.6094301\tbest: 0.6094301 (940)\ttotal: 3m 53s\tremaining: 37m 27s\n",
      "950:\tlearn: 0.5948426\ttest: 0.6094311\tbest: 0.6094146 (946)\ttotal: 3m 55s\tremaining: 37m 21s\n",
      "960:\tlearn: 0.5946910\ttest: 0.6094146\tbest: 0.6094102 (957)\ttotal: 3m 57s\tremaining: 37m 15s\n",
      "970:\tlearn: 0.5945655\ttest: 0.6094190\tbest: 0.6094102 (957)\ttotal: 3m 59s\tremaining: 37m 10s\n",
      "980:\tlearn: 0.5944328\ttest: 0.6094216\tbest: 0.6094102 (957)\ttotal: 4m 2s\tremaining: 37m 10s\n",
      "990:\tlearn: 0.5942998\ttest: 0.6093982\tbest: 0.6093934 (987)\ttotal: 4m 4s\tremaining: 37m 4s\n",
      "1000:\tlearn: 0.5941354\ttest: 0.6093635\tbest: 0.6093634 (997)\ttotal: 4m 6s\tremaining: 36m 59s\n",
      "1010:\tlearn: 0.5940130\ttest: 0.6093401\tbest: 0.6093401 (1010)\ttotal: 4m 8s\tremaining: 36m 52s\n",
      "1020:\tlearn: 0.5938605\ttest: 0.6093450\tbest: 0.6093344 (1011)\ttotal: 4m 10s\tremaining: 36m 46s\n",
      "1030:\tlearn: 0.5937053\ttest: 0.6093178\tbest: 0.6093156 (1027)\ttotal: 4m 13s\tremaining: 36m 41s\n",
      "1040:\tlearn: 0.5935642\ttest: 0.6093013\tbest: 0.6093013 (1040)\ttotal: 4m 15s\tremaining: 36m 35s\n",
      "1050:\tlearn: 0.5934192\ttest: 0.6092994\tbest: 0.6092904 (1044)\ttotal: 4m 17s\tremaining: 36m 29s\n",
      "1060:\tlearn: 0.5932713\ttest: 0.6093027\tbest: 0.6092904 (1044)\ttotal: 4m 19s\tremaining: 36m 24s\n",
      "1070:\tlearn: 0.5931286\ttest: 0.6092860\tbest: 0.6092825 (1067)\ttotal: 4m 21s\tremaining: 36m 17s\n",
      "1080:\tlearn: 0.5929770\ttest: 0.6092562\tbest: 0.6092562 (1080)\ttotal: 4m 23s\tremaining: 36m 12s\n",
      "1090:\tlearn: 0.5928268\ttest: 0.6092332\tbest: 0.6092318 (1089)\ttotal: 4m 25s\tremaining: 36m 7s\n",
      "1100:\tlearn: 0.5926635\ttest: 0.6092144\tbest: 0.6092136 (1099)\ttotal: 4m 27s\tremaining: 36m 2s\n",
      "1110:\tlearn: 0.5925184\ttest: 0.6092166\tbest: 0.6092069 (1103)\ttotal: 4m 29s\tremaining: 35m 58s\n",
      "1120:\tlearn: 0.5923785\ttest: 0.6091927\tbest: 0.6091887 (1118)\ttotal: 4m 31s\tremaining: 35m 52s\n",
      "1130:\tlearn: 0.5922515\ttest: 0.6091730\tbest: 0.6091688 (1129)\ttotal: 4m 33s\tremaining: 35m 46s\n",
      "1140:\tlearn: 0.5920961\ttest: 0.6091792\tbest: 0.6091688 (1129)\ttotal: 4m 35s\tremaining: 35m 41s\n",
      "1150:\tlearn: 0.5919516\ttest: 0.6091694\tbest: 0.6091667 (1148)\ttotal: 4m 37s\tremaining: 35m 37s\n",
      "1160:\tlearn: 0.5918151\ttest: 0.6091705\tbest: 0.6091667 (1148)\ttotal: 4m 40s\tremaining: 35m 33s\n",
      "1170:\tlearn: 0.5916768\ttest: 0.6091581\tbest: 0.6091581 (1170)\ttotal: 4m 42s\tremaining: 35m 29s\n",
      "1180:\tlearn: 0.5915465\ttest: 0.6091492\tbest: 0.6091492 (1180)\ttotal: 4m 44s\tremaining: 35m 25s\n",
      "1190:\tlearn: 0.5913827\ttest: 0.6091425\tbest: 0.6091384 (1184)\ttotal: 4m 47s\tremaining: 35m 25s\n",
      "1200:\tlearn: 0.5912458\ttest: 0.6091354\tbest: 0.6091340 (1199)\ttotal: 4m 51s\tremaining: 35m 33s\n",
      "1210:\tlearn: 0.5910936\ttest: 0.6091174\tbest: 0.6091173 (1204)\ttotal: 4m 53s\tremaining: 35m 29s\n",
      "1220:\tlearn: 0.5909592\ttest: 0.6091116\tbest: 0.6091049 (1215)\ttotal: 4m 56s\tremaining: 35m 29s\n",
      "1230:\tlearn: 0.5908275\ttest: 0.6091064\tbest: 0.6091028 (1227)\ttotal: 4m 58s\tremaining: 35m 29s\n",
      "1240:\tlearn: 0.5906891\ttest: 0.6090941\tbest: 0.6090941 (1240)\ttotal: 5m 1s\tremaining: 35m 26s\n",
      "1250:\tlearn: 0.5905458\ttest: 0.6091064\tbest: 0.6090941 (1240)\ttotal: 5m 4s\tremaining: 35m 26s\n",
      "1260:\tlearn: 0.5904287\ttest: 0.6091021\tbest: 0.6090941 (1240)\ttotal: 5m 6s\tremaining: 35m 23s\n",
      "1270:\tlearn: 0.5902956\ttest: 0.6091063\tbest: 0.6090941 (1240)\ttotal: 5m 8s\tremaining: 35m 19s\n",
      "1280:\tlearn: 0.5901413\ttest: 0.6091032\tbest: 0.6090941 (1240)\ttotal: 5m 10s\tremaining: 35m 15s\n",
      "1290:\tlearn: 0.5900259\ttest: 0.6091014\tbest: 0.6090926 (1282)\ttotal: 5m 13s\tremaining: 35m 13s\n",
      "1300:\tlearn: 0.5899173\ttest: 0.6090968\tbest: 0.6090926 (1282)\ttotal: 5m 15s\tremaining: 35m 10s\n",
      "1310:\tlearn: 0.5898067\ttest: 0.6090925\tbest: 0.6090889 (1308)\ttotal: 5m 17s\tremaining: 35m 5s\n",
      "1320:\tlearn: 0.5896751\ttest: 0.6090936\tbest: 0.6090878 (1312)\ttotal: 5m 20s\tremaining: 35m 3s\n",
      "1330:\tlearn: 0.5895432\ttest: 0.6090870\tbest: 0.6090859 (1327)\ttotal: 5m 22s\tremaining: 35m 2s\n",
      "1340:\tlearn: 0.5894179\ttest: 0.6090874\tbest: 0.6090859 (1327)\ttotal: 5m 25s\tremaining: 35m\n",
      "1350:\tlearn: 0.5892979\ttest: 0.6090802\tbest: 0.6090796 (1349)\ttotal: 5m 27s\tremaining: 34m 57s\n",
      "1360:\tlearn: 0.5891846\ttest: 0.6090685\tbest: 0.6090685 (1360)\ttotal: 5m 29s\tremaining: 34m 53s\n",
      "1370:\tlearn: 0.5890420\ttest: 0.6090450\tbest: 0.6090437 (1369)\ttotal: 5m 32s\tremaining: 34m 51s\n",
      "1380:\tlearn: 0.5889378\ttest: 0.6090265\tbest: 0.6090233 (1378)\ttotal: 5m 34s\tremaining: 34m 49s\n",
      "1390:\tlearn: 0.5888053\ttest: 0.6090250\tbest: 0.6090233 (1378)\ttotal: 5m 37s\tremaining: 34m 47s\n",
      "1400:\tlearn: 0.5886962\ttest: 0.6090335\tbest: 0.6090233 (1378)\ttotal: 5m 40s\tremaining: 34m 50s\n",
      "1410:\tlearn: 0.5885711\ttest: 0.6090225\tbest: 0.6090200 (1405)\ttotal: 5m 43s\tremaining: 34m 50s\n",
      "1420:\tlearn: 0.5884453\ttest: 0.6090180\tbest: 0.6090180 (1420)\ttotal: 5m 45s\tremaining: 34m 48s\n",
      "1430:\tlearn: 0.5883374\ttest: 0.6090204\tbest: 0.6090125 (1426)\ttotal: 5m 48s\tremaining: 34m 45s\n",
      "1440:\tlearn: 0.5882520\ttest: 0.6090029\tbest: 0.6090029 (1440)\ttotal: 5m 50s\tremaining: 34m 43s\n",
      "1450:\tlearn: 0.5881003\ttest: 0.6090035\tbest: 0.6089955 (1442)\ttotal: 5m 53s\tremaining: 34m 40s\n",
      "1460:\tlearn: 0.5879720\ttest: 0.6089865\tbest: 0.6089865 (1460)\ttotal: 5m 55s\tremaining: 34m 37s\n",
      "1470:\tlearn: 0.5878510\ttest: 0.6089828\tbest: 0.6089763 (1468)\ttotal: 5m 57s\tremaining: 34m 34s\n",
      "1480:\tlearn: 0.5877308\ttest: 0.6089952\tbest: 0.6089763 (1468)\ttotal: 6m\tremaining: 34m 30s\n",
      "1490:\tlearn: 0.5876112\ttest: 0.6089980\tbest: 0.6089763 (1468)\ttotal: 6m 2s\tremaining: 34m 27s\n",
      "1500:\tlearn: 0.5874965\ttest: 0.6090034\tbest: 0.6089763 (1468)\ttotal: 6m 4s\tremaining: 34m 25s\n",
      "1510:\tlearn: 0.5873635\ttest: 0.6090067\tbest: 0.6089763 (1468)\ttotal: 6m 7s\tremaining: 34m 22s\n",
      "1520:\tlearn: 0.5872195\ttest: 0.6089931\tbest: 0.6089763 (1468)\ttotal: 6m 9s\tremaining: 34m 20s\n",
      "1530:\tlearn: 0.5870856\ttest: 0.6089972\tbest: 0.6089763 (1468)\ttotal: 6m 11s\tremaining: 34m 17s\n",
      "1540:\tlearn: 0.5869541\ttest: 0.6089945\tbest: 0.6089763 (1468)\ttotal: 6m 14s\tremaining: 34m 15s\n",
      "1550:\tlearn: 0.5868415\ttest: 0.6089833\tbest: 0.6089763 (1468)\ttotal: 6m 16s\tremaining: 34m 12s\n",
      "1560:\tlearn: 0.5867170\ttest: 0.6089712\tbest: 0.6089712 (1560)\ttotal: 6m 19s\tremaining: 34m 9s\n",
      "1570:\tlearn: 0.5865869\ttest: 0.6089566\tbest: 0.6089537 (1569)\ttotal: 6m 21s\tremaining: 34m 8s\n",
      "1580:\tlearn: 0.5864558\ttest: 0.6089470\tbest: 0.6089449 (1578)\ttotal: 6m 25s\tremaining: 34m 11s\n",
      "1590:\tlearn: 0.5863480\ttest: 0.6089402\tbest: 0.6089392 (1589)\ttotal: 6m 27s\tremaining: 34m 9s\n",
      "1600:\tlearn: 0.5862188\ttest: 0.6089521\tbest: 0.6089392 (1589)\ttotal: 6m 30s\tremaining: 34m 7s\n",
      "1610:\tlearn: 0.5861036\ttest: 0.6089323\tbest: 0.6089302 (1608)\ttotal: 6m 32s\tremaining: 34m 3s\n",
      "1620:\tlearn: 0.5859730\ttest: 0.6089138\tbest: 0.6089078 (1619)\ttotal: 6m 34s\tremaining: 33m 59s\n",
      "1630:\tlearn: 0.5858308\ttest: 0.6088985\tbest: 0.6088985 (1630)\ttotal: 6m 36s\tremaining: 33m 55s\n",
      "1640:\tlearn: 0.5857143\ttest: 0.6089000\tbest: 0.6088954 (1632)\ttotal: 6m 38s\tremaining: 33m 51s\n",
      "1650:\tlearn: 0.5855950\ttest: 0.6088814\tbest: 0.6088775 (1645)\ttotal: 6m 41s\tremaining: 33m 48s\n",
      "1660:\tlearn: 0.5854728\ttest: 0.6088788\tbest: 0.6088691 (1654)\ttotal: 6m 43s\tremaining: 33m 44s\n",
      "1670:\tlearn: 0.5853552\ttest: 0.6088819\tbest: 0.6088691 (1654)\ttotal: 6m 45s\tremaining: 33m 40s\n",
      "1680:\tlearn: 0.5852260\ttest: 0.6088884\tbest: 0.6088691 (1654)\ttotal: 6m 47s\tremaining: 33m 36s\n",
      "1690:\tlearn: 0.5851159\ttest: 0.6088964\tbest: 0.6088691 (1654)\ttotal: 6m 49s\tremaining: 33m 32s\n",
      "1700:\tlearn: 0.5849764\ttest: 0.6089002\tbest: 0.6088691 (1654)\ttotal: 6m 51s\tremaining: 33m 28s\n",
      "1710:\tlearn: 0.5848426\ttest: 0.6088864\tbest: 0.6088691 (1654)\ttotal: 6m 54s\tremaining: 33m 30s\n",
      "1720:\tlearn: 0.5847191\ttest: 0.6088737\tbest: 0.6088691 (1654)\ttotal: 6m 57s\tremaining: 33m 29s\n",
      "1730:\tlearn: 0.5846103\ttest: 0.6088813\tbest: 0.6088691 (1654)\ttotal: 6m 59s\tremaining: 33m 25s\n",
      "1740:\tlearn: 0.5844812\ttest: 0.6088855\tbest: 0.6088691 (1654)\ttotal: 7m 1s\tremaining: 33m 21s\n",
      "1750:\tlearn: 0.5843676\ttest: 0.6088844\tbest: 0.6088691 (1654)\ttotal: 7m 4s\tremaining: 33m 17s\n",
      "1760:\tlearn: 0.5842436\ttest: 0.6088905\tbest: 0.6088691 (1654)\ttotal: 7m 6s\tremaining: 33m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770:\tlearn: 0.5841206\ttest: 0.6088852\tbest: 0.6088691 (1654)\ttotal: 7m 9s\tremaining: 33m 17s\n",
      "1780:\tlearn: 0.5840066\ttest: 0.6088909\tbest: 0.6088691 (1654)\ttotal: 7m 13s\tremaining: 33m 19s\n",
      "1790:\tlearn: 0.5838901\ttest: 0.6088834\tbest: 0.6088691 (1654)\ttotal: 7m 15s\tremaining: 33m 16s\n",
      "1800:\tlearn: 0.5837762\ttest: 0.6088907\tbest: 0.6088691 (1654)\ttotal: 7m 17s\tremaining: 33m 11s\n",
      "1810:\tlearn: 0.5836391\ttest: 0.6088761\tbest: 0.6088691 (1654)\ttotal: 7m 19s\tremaining: 33m 7s\n",
      "1820:\tlearn: 0.5835263\ttest: 0.6088845\tbest: 0.6088682 (1813)\ttotal: 7m 21s\tremaining: 33m 3s\n",
      "1830:\tlearn: 0.5834215\ttest: 0.6088851\tbest: 0.6088682 (1813)\ttotal: 7m 23s\tremaining: 32m 58s\n",
      "1840:\tlearn: 0.5833080\ttest: 0.6088971\tbest: 0.6088682 (1813)\ttotal: 7m 25s\tremaining: 32m 53s\n",
      "1850:\tlearn: 0.5831844\ttest: 0.6088829\tbest: 0.6088682 (1813)\ttotal: 7m 27s\tremaining: 32m 51s\n",
      "1860:\tlearn: 0.5830624\ttest: 0.6088894\tbest: 0.6088682 (1813)\ttotal: 7m 30s\tremaining: 32m 51s\n",
      "1870:\tlearn: 0.5829502\ttest: 0.6089005\tbest: 0.6088682 (1813)\ttotal: 7m 32s\tremaining: 32m 47s\n",
      "1880:\tlearn: 0.5828295\ttest: 0.6088942\tbest: 0.6088682 (1813)\ttotal: 7m 34s\tremaining: 32m 43s\n",
      "1890:\tlearn: 0.5827235\ttest: 0.6088833\tbest: 0.6088682 (1813)\ttotal: 7m 36s\tremaining: 32m 39s\n",
      "1900:\tlearn: 0.5826111\ttest: 0.6088864\tbest: 0.6088682 (1813)\ttotal: 7m 39s\tremaining: 32m 37s\n",
      "1910:\tlearn: 0.5825059\ttest: 0.6088799\tbest: 0.6088682 (1813)\ttotal: 7m 41s\tremaining: 32m 34s\n",
      "1920:\tlearn: 0.5823892\ttest: 0.6088686\tbest: 0.6088682 (1813)\ttotal: 7m 43s\tremaining: 32m 30s\n",
      "1930:\tlearn: 0.5822766\ttest: 0.6088514\tbest: 0.6088514 (1930)\ttotal: 7m 46s\tremaining: 32m 27s\n",
      "1940:\tlearn: 0.5821685\ttest: 0.6088544\tbest: 0.6088514 (1930)\ttotal: 7m 48s\tremaining: 32m 23s\n",
      "1950:\tlearn: 0.5820441\ttest: 0.6088392\tbest: 0.6088392 (1950)\ttotal: 7m 50s\tremaining: 32m 19s\n",
      "1960:\tlearn: 0.5819219\ttest: 0.6088542\tbest: 0.6088392 (1950)\ttotal: 7m 52s\tremaining: 32m 15s\n",
      "1970:\tlearn: 0.5818323\ttest: 0.6088525\tbest: 0.6088392 (1950)\ttotal: 7m 54s\tremaining: 32m 11s\n",
      "1980:\tlearn: 0.5817247\ttest: 0.6088452\tbest: 0.6088392 (1950)\ttotal: 7m 56s\tremaining: 32m 8s\n",
      "1990:\tlearn: 0.5815951\ttest: 0.6088404\tbest: 0.6088392 (1950)\ttotal: 8m\tremaining: 32m 13s\n",
      "2000:\tlearn: 0.5814915\ttest: 0.6088388\tbest: 0.6088369 (1996)\ttotal: 8m 3s\tremaining: 32m 12s\n",
      "2010:\tlearn: 0.5813626\ttest: 0.6088349\tbest: 0.6088343 (2009)\ttotal: 8m 5s\tremaining: 32m 10s\n",
      "2020:\tlearn: 0.5812442\ttest: 0.6088305\tbest: 0.6088291 (2015)\ttotal: 8m 8s\tremaining: 32m 9s\n",
      "2030:\tlearn: 0.5811200\ttest: 0.6088294\tbest: 0.6088260 (2029)\ttotal: 8m 11s\tremaining: 32m 7s\n",
      "2040:\tlearn: 0.5809945\ttest: 0.6088138\tbest: 0.6088138 (2040)\ttotal: 8m 13s\tremaining: 32m 5s\n",
      "2050:\tlearn: 0.5808878\ttest: 0.6088026\tbest: 0.6087976 (2047)\ttotal: 8m 17s\tremaining: 32m 6s\n",
      "2060:\tlearn: 0.5807652\ttest: 0.6088007\tbest: 0.6087974 (2053)\ttotal: 8m 19s\tremaining: 32m 5s\n",
      "2070:\tlearn: 0.5806444\ttest: 0.6087869\tbest: 0.6087869 (2070)\ttotal: 8m 23s\tremaining: 32m 5s\n",
      "2080:\tlearn: 0.5805391\ttest: 0.6087834\tbest: 0.6087757 (2075)\ttotal: 8m 26s\tremaining: 32m 6s\n",
      "2090:\tlearn: 0.5804181\ttest: 0.6087898\tbest: 0.6087757 (2075)\ttotal: 8m 28s\tremaining: 32m 5s\n",
      "2100:\tlearn: 0.5803075\ttest: 0.6087743\tbest: 0.6087743 (2100)\ttotal: 8m 32s\tremaining: 32m 6s\n",
      "2110:\tlearn: 0.5801982\ttest: 0.6087791\tbest: 0.6087740 (2102)\ttotal: 8m 34s\tremaining: 32m 4s\n",
      "2120:\tlearn: 0.5800881\ttest: 0.6087728\tbest: 0.6087672 (2116)\ttotal: 8m 37s\tremaining: 32m 2s\n",
      "2130:\tlearn: 0.5799885\ttest: 0.6087643\tbest: 0.6087628 (2129)\ttotal: 8m 40s\tremaining: 32m\n",
      "2140:\tlearn: 0.5798650\ttest: 0.6087571\tbest: 0.6087517 (2135)\ttotal: 8m 42s\tremaining: 31m 59s\n",
      "2150:\tlearn: 0.5797457\ttest: 0.6087635\tbest: 0.6087517 (2135)\ttotal: 8m 45s\tremaining: 31m 57s\n",
      "2160:\tlearn: 0.5796252\ttest: 0.6087711\tbest: 0.6087517 (2135)\ttotal: 8m 48s\tremaining: 31m 56s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-2d4b4ea29a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m       \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m       \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )  \n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   3842\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   3843\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3844\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   3845\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1724\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1726\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1727\u001b[0m             )\n\u001b[0;32m   1728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=10000,\n",
    "    learning_rate=0.1,\n",
    "    #task_type='GPU'\n",
    ")\n",
    "  \n",
    "model.fit(\n",
    "      x_train, y_train,\n",
    "      eval_set=(x_val, y_val),\n",
    "      verbose=10,\n",
    ")  \n",
    "\n",
    "print(model.get_best_score())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
