{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanda\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col=0)\n",
    "df_test = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_price                   0\n",
      "mid                          0\n",
      "opened_position_qty     172460\n",
      "closed_position_qty     172460\n",
      "transacted_qty               0\n",
      "d_open_interest              0\n",
      "bid1                         0\n",
      "bid2                         0\n",
      "bid3                         0\n",
      "bid4                         0\n",
      "bid5                         0\n",
      "ask1                         0\n",
      "ask2                         0\n",
      "ask3                         0\n",
      "ask4                         0\n",
      "ask5                         0\n",
      "bid1vol                      0\n",
      "bid2vol                      0\n",
      "bid3vol                      0\n",
      "bid4vol                      0\n",
      "bid5vol                      0\n",
      "ask1vol                      0\n",
      "ask2vol                      0\n",
      "ask3vol                      0\n",
      "ask4vol                      0\n",
      "ask5vol                      0\n",
      "y                            0\n",
      "dtype: int64\n",
      "last_price                  0\n",
      "mid                         0\n",
      "opened_position_qty     53656\n",
      "closed_position_qty     53656\n",
      "transacted_qty              0\n",
      "d_open_interest             0\n",
      "bid1                        0\n",
      "bid2                        0\n",
      "bid3                        0\n",
      "bid4                        0\n",
      "bid5                        0\n",
      "ask1                        0\n",
      "ask2                        0\n",
      "ask3                        0\n",
      "ask4                        0\n",
      "ask5                        0\n",
      "bid1vol                     0\n",
      "bid2vol                     0\n",
      "bid3vol                     0\n",
      "bid4vol                     0\n",
      "bid5vol                     0\n",
      "ask1vol                     0\n",
      "ask2vol                     0\n",
      "ask3vol                     0\n",
      "ask4vol                     0\n",
      "ask5vol                     0\n",
      "dtype: int64\n",
      "1.4005834444656124\n",
      "1.0\n",
      "1.9642765288626405\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# identify and replace missing values\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())\n",
    "\n",
    "print(df_train['opened_position_qty '].mean())\n",
    "print(df_train['opened_position_qty '].median())\n",
    "\n",
    "print(df_train['closed_position_qty'].mean())\n",
    "print(df_train['closed_position_qty'].median())\n",
    "\n",
    "# replace missing values with median (less sensitive to outliers)\n",
    "df_train['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_test['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_train['closed_position_qty'].fillna(df_train['closed_position_qty'].median(),inplace=True)\n",
    "df_test['closed_position_qty'].fillna(df_train['closed_position_qty'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    last_price       mid  opened_position_qty   closed_position_qty  \\\n",
      "id                                                                    \n",
      "1    -1.501678 -1.494346              2.464481            21.097156   \n",
      "2    -1.487008 -1.483343              2.987055            33.581616   \n",
      "3    -1.489453 -1.494346              0.896758            14.409052   \n",
      "4    -1.496788 -1.498013              0.896758            16.192547   \n",
      "6    -1.491898 -1.483343              0.374183            15.746673   \n",
      "\n",
      "    transacted_qty  d_open_interest      bid1      bid2      bid3      bid4  \\\n",
      "id                                                                            \n",
      "1        13.913985       -18.265229 -1.496986 -1.496637 -1.498903 -1.501215   \n",
      "2        21.583751       -29.330098 -1.487205 -1.486856 -1.489121 -1.488987   \n",
      "3         9.153441       -12.732794 -1.496986 -1.496637 -1.498903 -1.501215   \n",
      "4        10.211339       -14.860654 -1.499431 -1.501527 -1.503794 -1.503661   \n",
      "6         9.682390       -14.435082 -1.487205 -1.489301 -1.489121 -1.488987   \n",
      "\n",
      "      ...      bid1vol   bid2vol   bid3vol   bid4vol   bid5vol   ask1vol  \\\n",
      "id    ...                                                                  \n",
      "1     ...     0.742043  0.214423  1.050471 -0.802783  0.011052 -0.640954   \n",
      "2     ...    -0.194855 -0.766254 -0.242980  2.686636  0.970130 -0.640954   \n",
      "3     ...     1.444717  1.587372  1.235250 -0.628312 -0.308641 -0.419008   \n",
      "4     ...     2.381615  1.391237 -0.612538 -0.628312 -0.308641 -0.640954   \n",
      "6     ...    -0.663305  0.410559 -0.797316 -0.802783  1.769362  1.578509   \n",
      "\n",
      "     ask2vol   ask3vol   ask4vol   ask5vol  \n",
      "id                                          \n",
      "1  -0.168154 -0.221125 -0.708799  1.013890  \n",
      "2   2.040907  0.792224 -0.247674  0.440440  \n",
      "3   0.384111 -0.727800 -0.555091  0.727165  \n",
      "4  -0.352242 -0.727800  0.828287  1.300615  \n",
      "6   1.856818  0.792224 -0.401382  0.440440  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train = df_train[df_train.columns[:26]]\n",
    "y_train = df_train['y']\n",
    "x_test = df_test\n",
    "\n",
    "# Normalize training data by subtracting mean and scaling to unit variance\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_norm = std_scale.transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_norm, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "# Normalize testing data by using mean and SD of training set\n",
    "x_test_norm = std_scale.transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_norm, index=x_test.index, columns=x_test.columns) \n",
    "print(x_train.iloc[np.array([1, 2, 3, 4, 6])])\n",
    "#print(df_train.loc[df_train['id'] < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(x_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.1, noise_shape=None, seed=None),\n",
    "    keras.layers.Dense(2, activation=  'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 150s 282us/step - loss: 0.6283 - acc: 0.6473\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 147s 276us/step - loss: 0.6255 - acc: 0.6496\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 139s 261us/step - loss: 0.6248 - acc: 0.6505\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 139s 260us/step - loss: 0.6246 - acc: 0.6507\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 141s 264us/step - loss: 0.6245 - acc: 0.6512\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 144s 271us/step - loss: 0.6242 - acc: 0.6510\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 125s 234us/step - loss: 0.6240 - acc: 0.6517s - loss: 0.6240 - acc: 0.65\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 118s 222us/step - loss: 0.6239 - acc: 0.6518\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 119s 223us/step - loss: 0.6236 - acc: 0.6520\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 116s 217us/step - loss: 0.6236 - acc: 0.6517\n",
      "533142/533142 [==============================] - 50s 93us/step\n",
      "59238/59238 [==============================] - 5s 83us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 120s 225us/step - loss: 0.6245 - acc: 0.6510\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 124s 232us/step - loss: 0.6243 - acc: 0.6514\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 127s 238us/step - loss: 0.6242 - acc: 0.6511\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 136s 256us/step - loss: 0.6241 - acc: 0.6516\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 145s 272us/step - loss: 0.6240 - acc: 0.6515\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 147s 276us/step - loss: 0.6237 - acc: 0.6520\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 149s 280us/step - loss: 0.6239 - acc: 0.6516\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 147s 276us/step - loss: 0.6235 - acc: 0.6518\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 146s 273us/step - loss: 0.6236 - acc: 0.6520s - loss: 0.6236\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 138s 259us/step - loss: 0.6234 - acc: 0.6522s - loss - ETA: \n",
      "533142/533142 [==============================] - 55s 103us/step\n",
      "59238/59238 [==============================] - 10s 165us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 125s 235us/step - loss: 0.6242 - acc: 0.6510\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - ETA: 0s - loss: 0.6241 - acc: 0.651 - 139s 261us/step - loss: 0.6241 - acc: 0.6512\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 134s 251us/step - loss: 0.6242 - acc: 0.6509\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 122s 229us/step - loss: 0.6240 - acc: 0.6514\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 140s 262us/step - loss: 0.6240 - acc: 0.6512\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 160s 300us/step - loss: 0.6239 - acc: 0.6511\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 228s 427us/step - loss: 0.6238 - acc: 0.6516\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 154s 289us/step - loss: 0.6235 - acc: 0.6518s - l - ETA: 3s - los - ETA: 2s - loss: 0.6236 - a - ETA: 1s - loss: 0.6236  - ETA: 0s - loss: 0.6236 - acc: \n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 146s 273us/step - loss: 0.6236 - acc: 0.6518\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 123s 231us/step - loss: 0.6234 - acc: 0.6520\n",
      "533142/533142 [==============================] - 55s 103us/step\n",
      "59238/59238 [==============================] - 7s 117us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 143s 268us/step - loss: 0.6247 - acc: 0.6507\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 146s 274us/step - loss: 0.6247 - acc: 0.6505\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 134s 252us/step - loss: 0.6246 - acc: 0.6510s -  - ETA: 2s - los - ETA: 1s - loss: 0.6\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 139s 260us/step - loss: 0.6245 - acc: 0.6508s - loss: 0.\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 126s 237us/step - loss: 0.6245 - acc: 0.6506\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 111s 209us/step - loss: 0.6244 - acc: 0.6506\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 114s 213us/step - loss: 0.6243 - acc: 0.6511\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 115s 216us/step - loss: 0.6242 - acc: 0.6508\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 114s 213us/step - loss: 0.6243 - acc: 0.6508\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 120s 225us/step - loss: 0.6241 - acc: 0.6509\n",
      "533142/533142 [==============================] - 47s 89us/step\n",
      "59238/59238 [==============================] - 6s 96us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 116s 218us/step - loss: 0.6228 - acc: 0.6533\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 115s 215us/step - loss: 0.6226 - acc: 0.6530\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 125s 234us/step - loss: 0.6225 - acc: 0.6528\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 110s 206us/step - loss: 0.6225 - acc: 0.6531\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 117s 219us/step - loss: 0.6223 - acc: 0.6533\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 111s 208us/step - loss: 0.6223 - acc: 0.6533\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 113s 211us/step - loss: 0.6222 - acc: 0.6536\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 114s 214us/step - loss: 0.6222 - acc: 0.6536\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 131s 246us/step - loss: 0.6222 - acc: 0.6536\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 132s 248us/step - loss: 0.6219 - acc: 0.6535s - loss: 0.6219 - acc: 0.65 - ETA: 3s - loss - ETA: 1s\n",
      "533142/533142 [==============================] - 49s 92us/step\n",
      "59238/59238 [==============================] - 5s 91us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 130s 244us/step - loss: 0.6204 - acc: 0.6549\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 129s 243us/step - loss: 0.6204 - acc: 0.6552s - loss: 0.6204 - \n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 125s 234us/step - loss: 0.6203 - acc: 0.6556\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 122s 230us/step - loss: 0.6203 - acc: 0.6552s - loss: 0.6203 - acc: 0 - ETA: 0s - loss: 0.6203 - acc: 0\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 122s 229us/step - loss: 0.6202 - acc: 0.6557\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 126s 237us/step - loss: 0.6200 - acc: 0.6558\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 129s 242us/step - loss: 0.6202 - acc: 0.6560\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 162s 305us/step - loss: 0.6200 - acc: 0.6560\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 138s 259us/step - loss: 0.6200 - acc: 0.6564\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 133s 249us/step - loss: 0.6199 - acc: 0.6562\n",
      "533142/533142 [==============================] - 57s 107us/step\n",
      "59238/59238 [==============================] - 5s 85us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 173s 325us/step - loss: 0.6213 - acc: 0.6539s - loss: 0.6214 - a\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 201s 377us/step - loss: 0.6214 - acc: 0.6540\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 172s 323us/step - loss: 0.6211 - acc: 0.6544\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 172s 322us/step - loss: 0.6210 - acc: 0.6537\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 169s 316us/step - loss: 0.6211 - acc: 0.6543\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 167s 314us/step - loss: 0.6209 - acc: 0.6547\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533142/533142 [==============================] - 118s 222us/step - loss: 0.6207 - acc: 0.6547\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 110s 206us/step - loss: 0.6208 - acc: 0.6546\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 109s 204us/step - loss: 0.6206 - acc: 0.6549\n",
      "533142/533142 [==============================] - 41s 77us/step\n",
      "59238/59238 [==============================] - 5s 80us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 108s 202us/step - loss: 0.6219 - acc: 0.6530\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 108s 202us/step - loss: 0.6219 - acc: 0.6533\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 107s 201us/step - loss: 0.6218 - acc: 0.6531\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 107s 201us/step - loss: 0.6216 - acc: 0.6536s - lo - ETA: 0s - loss: 0.62\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 25324s 47ms/step - loss: 0.6218 - acc: 0.6532\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 156s 293us/step - loss: 0.6216 - acc: 0.6533\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 146s 274us/step - loss: 0.6216 - acc: 0.6531\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 157s 295us/step - loss: 0.6213 - acc: 0.6534\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 137s 257us/step - loss: 0.6213 - acc: 0.6535\n",
      "533142/533142 [==============================] - 57s 106us/step\n",
      "59238/59238 [==============================] - 6s 110us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 138s 260us/step - loss: 0.6192 - acc: 0.6560\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 138s 259us/step - loss: 0.6194 - acc: 0.6561\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 139s 261us/step - loss: 0.6190 - acc: 0.6565\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 137s 258us/step - loss: 0.6191 - acc: 0.6566\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 112s 210us/step - loss: 0.6190 - acc: 0.6563\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 111s 208us/step - loss: 0.6189 - acc: 0.6569\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 126s 236us/step - loss: 0.6185 - acc: 0.6569\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 3125s 6ms/step - loss: 0.6187 - acc: 0.6568\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 174s 326us/step - loss: 0.6186 - acc: 0.6573\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 173s 324us/step - loss: 0.6186 - acc: 0.6565\n",
      "533142/533142 [==============================] - 92s 173us/step\n",
      "59238/59238 [==============================] - 10s 166us/step\n",
      "Epoch 1/10\n",
      "533142/533142 [==============================] - 224s 420us/step - loss: 0.6180 - acc: 0.6583s - loss: 0.6181 - - ETA: 9s - loss: 0. - ETA: 2s\n",
      "Epoch 2/10\n",
      "533142/533142 [==============================] - 184s 344us/step - loss: 0.6181 - acc: 0.6578\n",
      "Epoch 3/10\n",
      "533142/533142 [==============================] - 181s 340us/step - loss: 0.6178 - acc: 0.6581\n",
      "Epoch 4/10\n",
      "533142/533142 [==============================] - 185s 348us/step - loss: 0.6178 - acc: 0.6584\n",
      "Epoch 5/10\n",
      "533142/533142 [==============================] - 177s 331us/step - loss: 0.6177 - acc: 0.6578\n",
      "Epoch 6/10\n",
      "533142/533142 [==============================] - 170s 319us/step - loss: 0.6178 - acc: 0.6579\n",
      "Epoch 7/10\n",
      "533142/533142 [==============================] - 170s 318us/step - loss: 0.6178 - acc: 0.6582\n",
      "Epoch 8/10\n",
      "533142/533142 [==============================] - 167s 313us/step - loss: 0.6180 - acc: 0.6580\n",
      "Epoch 9/10\n",
      "533142/533142 [==============================] - 174s 326us/step - loss: 0.6177 - acc: 0.6578\n",
      "Epoch 10/10\n",
      "533142/533142 [==============================] - 173s 324us/step - loss: 0.6173 - acc: 0.6579\n",
      "533142/533142 [==============================] - 76s 143us/step\n",
      "59238/59238 [==============================] - 8s 143us/step\n",
      "In Sample Accuracy: 0.6544969257718748\n",
      "Out of Sample Accuracy: 0.652071305580525\n"
     ]
    }
   ],
   "source": [
    "num_fold = 10\n",
    "index = np.array(range(len(x_train)))\n",
    "train_error = 0\n",
    "val_error = 0\n",
    "kf = KFold(n_splits=num_fold)\n",
    "for train_index, test_index in kf.split(index):\n",
    "    x_train_val, x_test_val = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "    y_train_val, y_test_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    train_model = model.fit(x_train_val, y_train_val, epochs= 10, batch_size = 128)\n",
    "    eval_train = model.evaluate(x_train_val, y_train_val)\n",
    "    eval_test = model.evaluate(x_test_val, y_test_val)\n",
    "    train_error += eval_train[1] / num_fold\n",
    "    val_error += eval_test[1] / num_fold\n",
    "print(\"In Sample Accuracy: \" + str(train_error))\n",
    "print(\"Out of Sample Accuracy: \" + str(val_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = model.predict_proba(x_test)[:,1]\n",
    "df_test[['Predicted']].to_csv('submission4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
