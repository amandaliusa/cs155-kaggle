{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanda\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col=0)\n",
    "df_test = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_price                   0\n",
      "mid                          0\n",
      "opened_position_qty     172460\n",
      "closed_position_qty     172460\n",
      "transacted_qty               0\n",
      "d_open_interest              0\n",
      "bid1                         0\n",
      "bid2                         0\n",
      "bid3                         0\n",
      "bid4                         0\n",
      "bid5                         0\n",
      "ask1                         0\n",
      "ask2                         0\n",
      "ask3                         0\n",
      "ask4                         0\n",
      "ask5                         0\n",
      "bid1vol                      0\n",
      "bid2vol                      0\n",
      "bid3vol                      0\n",
      "bid4vol                      0\n",
      "bid5vol                      0\n",
      "ask1vol                      0\n",
      "ask2vol                      0\n",
      "ask3vol                      0\n",
      "ask4vol                      0\n",
      "ask5vol                      0\n",
      "y                            0\n",
      "dtype: int64\n",
      "last_price                  0\n",
      "mid                         0\n",
      "opened_position_qty     53656\n",
      "closed_position_qty     53656\n",
      "transacted_qty              0\n",
      "d_open_interest             0\n",
      "bid1                        0\n",
      "bid2                        0\n",
      "bid3                        0\n",
      "bid4                        0\n",
      "bid5                        0\n",
      "ask1                        0\n",
      "ask2                        0\n",
      "ask3                        0\n",
      "ask4                        0\n",
      "ask5                        0\n",
      "bid1vol                     0\n",
      "bid2vol                     0\n",
      "bid3vol                     0\n",
      "bid4vol                     0\n",
      "bid5vol                     0\n",
      "ask1vol                     0\n",
      "ask2vol                     0\n",
      "ask3vol                     0\n",
      "ask4vol                     0\n",
      "ask5vol                     0\n",
      "dtype: int64\n",
      "1.4005834444656124\n",
      "1.0\n",
      "1.9642765288626405\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# identify and replace missing values\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())\n",
    "\n",
    "print(df_train['opened_position_qty '].mean())\n",
    "print(df_train['opened_position_qty '].median())\n",
    "\n",
    "print(df_train['closed_position_qty'].mean())\n",
    "print(df_train['closed_position_qty'].median())\n",
    "\n",
    "# replace missing values with median (less sensitive to outliers)\n",
    "df_train['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_test['opened_position_qty '].fillna(df_train['opened_position_qty '].median(),inplace=True)\n",
    "df_train['closed_position_qty'].fillna(df_train['closed_position_qty'].median(),inplace=True)\n",
    "df_test['closed_position_qty'].fillna(df_train['closed_position_qty'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train = df_train[df_train.columns[:26]]\n",
    "y_train = df_train['y']\n",
    "x_test = df_test\n",
    "\n",
    "# Normalize training data by subtracting mean and scaling to unit variance\n",
    "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_norm = std_scale.transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_norm, index=x_train.index, columns=x_train.columns)\n",
    "\n",
    "# Normalize testing data by using mean and SD of training set\n",
    "x_test_norm = std_scale.transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_norm, index=x_test.index, columns=x_test.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    " keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(x_train.shape[1],)),\n",
    " keras.layers.Dense(128, activation=tf.nn.relu),\n",
    " keras.layers.Dense(256, activation=tf.nn.relu),\n",
    " keras.layers.Dense(512, activation=tf.nn.relu),\n",
    " keras.layers.Dense(2, activation=  'softmax')\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "592380/592380 [==============================] - 25s 42us/step - loss: 0.6276 - acc: 0.6481\n",
      "Epoch 2/30\n",
      "592380/592380 [==============================] - 30s 50us/step - loss: 0.6251 - acc: 0.6501\n",
      "Epoch 3/30\n",
      "592380/592380 [==============================] - 29s 48us/step - loss: 0.6244 - acc: 0.6515\n",
      "Epoch 4/30\n",
      "592380/592380 [==============================] - 31s 52us/step - loss: 0.6240 - acc: 0.6517\n",
      "Epoch 5/30\n",
      "592380/592380 [==============================] - 31s 52us/step - loss: 0.6237 - acc: 0.6521\n",
      "Epoch 6/30\n",
      "592380/592380 [==============================] - 29s 50us/step - loss: 0.6236 - acc: 0.6521\n",
      "Epoch 7/30\n",
      "592380/592380 [==============================] - 27s 45us/step - loss: 0.6233 - acc: 0.6526\n",
      "Epoch 8/30\n",
      "592380/592380 [==============================] - 27s 45us/step - loss: 0.6231 - acc: 0.6529\n",
      "Epoch 9/30\n",
      "592380/592380 [==============================] - 26s 43us/step - loss: 0.6229 - acc: 0.6528\n",
      "Epoch 10/30\n",
      "592380/592380 [==============================] - 29s 48us/step - loss: 0.6227 - acc: 0.6528\n",
      "Epoch 11/30\n",
      "592380/592380 [==============================] - 25s 42us/step - loss: 0.6225 - acc: 0.6534\n",
      "Epoch 12/30\n",
      "592380/592380 [==============================] - 25s 42us/step - loss: 0.6224 - acc: 0.6533\n",
      "Epoch 13/30\n",
      "592380/592380 [==============================] - 25s 42us/step - loss: 0.6222 - acc: 0.6533\n",
      "Epoch 14/30\n",
      "592380/592380 [==============================] - 24s 41us/step - loss: 0.6219 - acc: 0.6537\n",
      "Epoch 15/30\n",
      "592380/592380 [==============================] - 27s 45us/step - loss: 0.6218 - acc: 0.6541\n",
      "Epoch 16/30\n",
      "592380/592380 [==============================] - 36s 61us/step - loss: 0.6215 - acc: 0.6542\n",
      "Epoch 17/30\n",
      "592380/592380 [==============================] - 26s 45us/step - loss: 0.6213 - acc: 0.6548\n",
      "Epoch 18/30\n",
      "592380/592380 [==============================] - 25s 43us/step - loss: 0.6210 - acc: 0.6548\n",
      "Epoch 19/30\n",
      "592380/592380 [==============================] - 25s 43us/step - loss: 0.6209 - acc: 0.6552\n",
      "Epoch 20/30\n",
      "592380/592380 [==============================] - 26s 43us/step - loss: 0.6207 - acc: 0.6548\n",
      "Epoch 21/30\n",
      "592380/592380 [==============================] - 25s 43us/step - loss: 0.6204 - acc: 0.6557\n",
      "Epoch 22/30\n",
      "592380/592380 [==============================] - 26s 43us/step - loss: 0.6202 - acc: 0.6558\n",
      "Epoch 23/30\n",
      "592380/592380 [==============================] - 25s 42us/step - loss: 0.6199 - acc: 0.6562\n",
      "Epoch 24/30\n",
      "592380/592380 [==============================] - 25s 42us/step - loss: 0.6196 - acc: 0.6560\n",
      "Epoch 25/30\n",
      "592380/592380 [==============================] - 26s 44us/step - loss: 0.6194 - acc: 0.6565\n",
      "Epoch 26/30\n",
      "592380/592380 [==============================] - 28s 47us/step - loss: 0.6191 - acc: 0.6564\n",
      "Epoch 27/30\n",
      " 33536/592380 [>.............................] - ETA: 27s - loss: 0.6208 - acc: 0.6554"
     ]
    }
   ],
   "source": [
    "train_model = model.fit(\n",
    " x_train, y_train,\n",
    " epochs= 30, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Predicted'] = model.predict_proba(x_test)[:,1]\n",
    "df_test[['Predicted']].to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
